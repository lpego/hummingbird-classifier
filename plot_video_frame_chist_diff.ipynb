{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73982284",
   "metadata": {},
   "source": [
    "# Plot local color histogram differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39fe14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a976220",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '././results_diffs/humbs//FH102_02_processed_chist_diff_new.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m df_change = df_change.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mcenter_idx\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     13\u001b[39m results_folder = \u001b[33m\"\u001b[39m\u001b[33m./results_diffs/humbs/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df_change_new = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresults_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvideo_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_processed_chist_diff_new.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m df_change_new.index = df_change_new[\u001b[33m\"\u001b[39m\u001b[33mcenter_idx\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     19\u001b[39m df_change_new = df_change_new.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mcenter_idx\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/miniconda3/envs/hucl/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/miniconda3/envs/hucl/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/miniconda3/envs/hucl/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/miniconda3/envs/hucl/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/miniconda3/envs/hucl/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '././results_diffs/humbs//FH102_02_processed_chist_diff_new.csv'"
     ]
    }
   ],
   "source": [
    "# Read the CSV results\n",
    "video_name = \"FH\" + \"102_02\"\n",
    "# video_name = \"PICT7_16DD_2022-07-30_06-00_006\"\n",
    "\n",
    "results_folder = \"./results_diffs/humbs/\"\n",
    "df_change = pd.read_csv(\n",
    "    f\"./{results_folder}/{video_name}_processed_chist_diff.csv\"\n",
    ")\n",
    "\n",
    "df_change.index = df_change[\"center_idx\"]\n",
    "df_change = df_change.drop(columns=[\"center_idx\"])\n",
    "\n",
    "# read the yaml config as well\n",
    "with open(f\"./{results_folder}/{video_name}_chist_config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "extension = \"avi\" #config[\"video_processing\"][\"extension\"]\n",
    "filename = f\"./data/{video_name}.{extension}\"\n",
    "\n",
    "# print config nicely\n",
    "for key, value in config.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_value in value.items():\n",
    "            print(f\"  {sub_key}: {sub_value}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662f12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # Plotting the results for all columns in the dataframe starting with \"std_diff_\" in the same axes\n",
    "    ax = plt.figure(figsize=(12, 6)).add_subplot(111)\n",
    "    # for column in df_change.columns:\n",
    "        # plt.plot(df_change.index, df_change[column], label=column, alpha=0.7)\n",
    "\n",
    "    plt.plot(df_change.index, df_change[\"stdev_magn_diff_chist\"].diff().abs(), label=\"diff abs\", color='blue', alpha=0.7)\n",
    "    plt.plot(df_change.index, df_change[\"stdev_magn_diff_chist\"], label=\"mag patch\", color='red', alpha=0.7)\n",
    "\n",
    "    for x in range(1, df_change.index.max(), 500):\n",
    "        ax.axvline(x=x, color='gray', linestyle='--', linewidth=0.5, zorder=0)\n",
    "        ax.grid(axis='y', linestyle='--', linewidth=0.5, color='gray', zorder=0)\n",
    "\n",
    "    plt.title(\"stdev_magn_diff_chist\")\n",
    "    plt.xlabel(\"Frame Index\")\n",
    "    plt.ylabel(\"Standard Deviation\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36016ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth CSV and extract FH401_01 rows\n",
    "gt = pd.read_csv('./data/Weinstein2018MEE_ground_truth.csv')\n",
    "gt_video = gt[gt['Video'] == video_name]\n",
    "gt_video = gt_video.set_index('Frame', drop=False)\n",
    "\n",
    "# deduplicate the index of ground truth\n",
    "gt_video = gt_video[~gt_video.index.duplicated(keep='first')]\n",
    "# gt_video[['Frame', 'Truth']]\n",
    "print(f\"number of labels in ground truth: \\n {gt_video.groupby('Truth').size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0359aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - 1 norm\n",
    "df_change['aggregated_diff'] = (df_change['stdev_magn_diff_chist'] - df_change['stdev_magn_diff_chist'].min()) / (df_change['stdev_magn_diff_chist'].max() - df_change['stdev_magn_diff_chist'].min())\n",
    "# df_change['aggregated_diff'] = df_change['stdev_magn_diff_chist']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 2))\n",
    "ax.plot(df_change.index, df_change['aggregated_diff'], label='aggregated_diff', color='orange', alpha=0.7)\n",
    "# ax.plot(df_change.index, df_change['aggregated_diff'].diff().abs(), label='aggregated_diff.diff.abs', color='green')\n",
    "\n",
    "for x in range(1, df_change.index.max(), 500):\n",
    "    ax.axvline(x=x, color='gray', linestyle='--', linewidth=0.5, zorder=0)\n",
    "    ax.grid(axis='y', linestyle='--', linewidth=0.5, color='gray', zorder=0)\n",
    "\n",
    "# Only plot if ground truth is available\n",
    "if not gt_video.empty:\n",
    "    # Arrow up for Positive, arrow down for Negative\n",
    "    positives = gt_video[gt_video['Truth'].str.lower() == 'positive']\n",
    "    negatives = gt_video[gt_video['Truth'].str.lower() == 'negative']\n",
    "\n",
    "    ax.scatter(positives.index, [1.01] * len(positives), marker='v', color='red', label='Positive (GT)', zorder=5)\n",
    "    ax.scatter(negatives.index, [-0.05] * len(negatives), marker='^', color='blue', label='Negative (GT)', zorder=5)\n",
    "    \n",
    "    # Annotate positive markers with frame IDs, spreading out text if labels are close\n",
    "    # last_frame_id = None\n",
    "    # c = 0\n",
    "    # for frame_id in positives.index:\n",
    "    #     if last_frame_id is not None and abs(frame_id - last_frame_id) < 100:  # Adjust threshold as needed\n",
    "    #         offset = 1.1 + 0.25 * c  # Add fixed offset of 1 if condition is true\n",
    "    #         ax.text(frame_id, offset, str(frame_id), color='red', fontsize=8, ha='center')  # Spread out\n",
    "    #         c += 1\n",
    "    #     else:\n",
    "    #         c = 0\n",
    "    #         ax.text(frame_id, 1.3, str(frame_id), color='red', fontsize=8, ha='center')\n",
    "    #     last_frame_id = frame_id\n",
    "\n",
    "ax.set_ylabel('aggregated_diff')\n",
    "ax.set_xlabel('center_idx')\n",
    "ax.legend()\n",
    "\n",
    "plt.title('Aggregated Diff with Ground Truth Arrows')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c136a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 100\n",
    "if top_k > 1:\n",
    "    top_k_frames = df_change.nlargest(top_k, 'aggregated_diff')\n",
    "else:\n",
    "    top_k_frames = df_change[df_change['aggregated_diff'] > top_k]\n",
    "    \n",
    "top_k_frames = top_k_frames.sort_values(by='aggregated_diff', ascending=False)\n",
    "\n",
    "chunk_size = 5\n",
    "top_k_frames = top_k_frames.iloc[:len(top_k_frames) - len(top_k_frames) % chunk_size]\n",
    "\n",
    "print(top_k_frames[['aggregated_diff']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9faf897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from torchcodec.decoders import VideoDecoder\n",
    "\n",
    "video_reader = VideoDecoder(filename)\n",
    "\n",
    "\n",
    "# Set the number of random frames to sample\n",
    "num_frames = 100\n",
    "\n",
    "# define the crop box (left, top, right, bottom)\n",
    "crop_box = config[\"preprocessing\"][\"crop_box\"]\n",
    "\n",
    "if 0:\n",
    "    # Generate random frame indices\n",
    "    random_indices = random.sample(range(len(video_reader)), num_frames)\n",
    "\n",
    "    # Initialize an array to accumulate pixel values\n",
    "    average_frame = None\n",
    "\n",
    "    # Iterate through the random frame indices and accumulate pixel values\n",
    "    for idx in random_indices:\n",
    "        frame = video_reader[idx].permute(1, 2, 0).numpy()  # Convert frame to numpy array (HWC format)\n",
    "        if average_frame is None:\n",
    "            average_frame = np.zeros_like(frame, dtype=np.float64)\n",
    "        average_frame += frame\n",
    "\n",
    "    # Compute the average frame\n",
    "    average_frame /= num_frames\n",
    "\n",
    "    # Convert the average frame back to uint8 for visualization\n",
    "    average_frame = average_frame.astype(np.uint8)\n",
    "\n",
    "    # Display the average frame\n",
    "    plt.imshow(average_frame)\n",
    "    plt.title(\"Average Frame\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d388b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 5  # Number of frames per group\n",
    "chunks = [top_k_frames.index[i:i + chunk_size] for i in range(0, len(top_k_frames), chunk_size)]\n",
    "\n",
    "for chunk_idx, chunk in enumerate(chunks):\n",
    "    fig, axes = plt.subplots(1, len(chunk), figsize=(15, 7))\n",
    "    for i, frame_idx in enumerate(chunk):\n",
    "\n",
    "        frame = video_reader[frame_idx]\n",
    "        # frame_before = average_frame # \n",
    "        # frame_before = video_reader[frame_idx - 1]\n",
    "\n",
    "        # Convert the frame from torch tensor to numpy array for plotting\n",
    "        frame_rgb = frame.permute(1, 2, 0) #.numpy().astype(np.float64)  # Assuming frame is in CHW format\n",
    "        \n",
    "        # Plot the frame\n",
    "        axes[i].imshow(frame_rgb)\n",
    "        if crop_box:\n",
    "            # Show the borders of crop, if crop_box is defined\n",
    "            x, y, w, h = crop_box\n",
    "            rect = plt.Rectangle((x, y), w, h, linewidth=2, edgecolor='red', facecolor='none')\n",
    "            axes[i].add_patch(rect)\n",
    "            \n",
    "        axes[i].set_title(f\"Frame {frame_idx}, score: {top_k_frames.loc[frame_idx, 'aggregated_diff']:.4f}\")\n",
    "        axes[i].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e33ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _video_frame_chist_diff import preprocess_frame, compute_patch_histograms, plot_original_triplet, visualize_histogram_difference_patch_image\n",
    "\n",
    "frame_skip = config[\"video_processing\"][\"frame_skip\"]  # Number of frames to skip for comparison\n",
    "patch_size = config[\"histogram_analysis\"][\"patch_size\"][\"coordinates\"]  # Size of the patches for histogram analysis\n",
    "bins = config[\"histogram_analysis\"][\"bins\"]  # Number of bins for histogram analysis \n",
    "threshold = config[\"histogram_analysis\"][\"threshold\"] # Threshold for histogram difference normalization\n",
    "threshold = threshold if threshold is not None else 3 * bins # Ensure threshold is positive\n",
    "\n",
    "# Read a specific frame from the video\n",
    "\n",
    "for frame_index in top_k_frames.index[:20]:\n",
    "    # frame_index = top_k_frames.index[0]  # Use the first frame from the top_k_frames\n",
    "    # frame_index = positives.index[0] - 1  # Use the first frame from the top_k_frames\n",
    "\n",
    "    # Buffer for preprocessed frames and histograms\n",
    "    frame_buffer = []\n",
    "    hist_buffer = []\n",
    "\n",
    "    for i in [frame_index-frame_skip, frame_index, frame_index + frame_skip]:\n",
    "        frame = video_reader[i].permute(1, 2, 0).cpu().numpy()\n",
    "        pframe = preprocess_frame(frame, crop_box=crop_box)\n",
    "        hist = compute_patch_histograms(pframe, patch_size=patch_size, bins=bins)\n",
    "        frame_buffer.append(pframe)\n",
    "        hist_buffer.append(hist)\n",
    "\n",
    "    # Use buffer for computation\n",
    "    hist1 = hist_buffer[0] # / hist1.sum(axis=1, keepdims=True)\n",
    "    hist2 = hist_buffer[1] # / hist2.sum(axis=1, keepdims=True)\n",
    "    hist3 = hist_buffer[2] # / hist3.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    pframe1 = frame_buffer[0]\n",
    "    pframe2 = frame_buffer[1]\n",
    "    pframe3 = frame_buffer[2]\n",
    "\n",
    "    hist_diff = np.linalg.norm(hist2 - hist1, axis=1) + np.linalg.norm(\n",
    "        hist3 - hist2, axis=1\n",
    "    )\n",
    "\n",
    "    normalized_diff = np.minimum(hist_diff, threshold) / threshold\n",
    "    std_dev = np.std(normalized_diff)\n",
    "\n",
    "    plot_original_triplet(pframe1, pframe2, pframe3)\n",
    "    visualize_histogram_difference_patch_image(\n",
    "        pframe1, pframe2, normalized_diff, patch_size, viz_threshold=0.4,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the results\n",
    "results = []\n",
    "buff = 1\n",
    "\n",
    "sorted_scores = df_change.sort_values(by='aggregated_diff', ascending=False)\n",
    "\n",
    "# Iterate through all top_10_frames\n",
    "for frame in sorted_scores.index:\n",
    "    is_within_range = any((positives['Frame'] >= frame - buff) & (positives['Frame'] <= frame + buff))\n",
    "    results.append({'Frame': frame, f'within_{buff}_positive': is_within_range})\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# print(results_df.head(20))\n",
    "\n",
    "# Create a DataFrame to store precision and recall values\n",
    "precision_recall_data = []\n",
    "\n",
    "for k in list(range(10,201,10)) + list(range(200, 1001, 100)) + list(range(1000, 2001, 500)):\n",
    "    precision_at_k = results_df[f'within_{buff}_positive'].iloc[:k].sum() / k\n",
    "    true_positives = results_df[\"Frame\"].iloc[:k].isin(positives[\"Frame\"])\n",
    "    recall_at_k = true_positives.sum() / len(positives)\n",
    "    \n",
    "    precision_recall_data.append({'k': k, 'Precision': precision_at_k, 'Recall': recall_at_k})\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "precision_recall_df = pd.DataFrame(precision_recall_data)\n",
    "\n",
    "# Plot precision and recall curves with log x-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(precision_recall_df['k'], precision_recall_df['Precision'], label='Precision', marker='o')\n",
    "plt.plot(precision_recall_df['k'], precision_recall_df['Recall'], label='Recall', marker='o')\n",
    "plt.axvline(x=len(positives), color='red', linestyle='--', label='Actual Positives')\n",
    "# plt.xscale('log')  # Set x-axis to logarithmic scale\n",
    "plt.title(f'Precision and Recall Curves, actual positives: {len(positives)}')\n",
    "plt.xlabel('Top-k')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(precision_recall_df['Recall'], precision_recall_df['Precision'], label='Precision-Recall Curve', marker='o')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print(precision_recall_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d8b67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c752353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb01c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hucl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
